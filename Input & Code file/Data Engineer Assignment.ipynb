{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7f65a5",
   "metadata": {},
   "source": [
    "## BLACKCOFFER DATA ENGINEER ASSIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2812bcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f8284f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URL_ID</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bctech2011</td>\n",
       "      <td>https://insights.blackcoffer.com/ml-and-ai-bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bctech2012</td>\n",
       "      <td>https://insights.blackcoffer.com/streamlined-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bctech2013</td>\n",
       "      <td>https://insights.blackcoffer.com/efficient-dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bctech2014</td>\n",
       "      <td>https://insights.blackcoffer.com/effective-man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bctech2015</td>\n",
       "      <td>https://insights.blackcoffer.com/streamlined-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>bctech2153</td>\n",
       "      <td>https://insights.blackcoffer.com/population-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>bctech2154</td>\n",
       "      <td>https://insights.blackcoffer.com/google-lsa-ap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>bctech2155</td>\n",
       "      <td>https://insights.blackcoffer.com/healthcare-da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>bctech2156</td>\n",
       "      <td>https://insights.blackcoffer.com/budget-sales-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>bctech2157</td>\n",
       "      <td>https://insights.blackcoffer.com/amazon-buy-bo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         URL_ID                                                URL\n",
       "0    bctech2011  https://insights.blackcoffer.com/ml-and-ai-bas...\n",
       "1    bctech2012  https://insights.blackcoffer.com/streamlined-i...\n",
       "2    bctech2013  https://insights.blackcoffer.com/efficient-dat...\n",
       "3    bctech2014  https://insights.blackcoffer.com/effective-man...\n",
       "4    bctech2015  https://insights.blackcoffer.com/streamlined-t...\n",
       "..          ...                                                ...\n",
       "142  bctech2153  https://insights.blackcoffer.com/population-an...\n",
       "143  bctech2154  https://insights.blackcoffer.com/google-lsa-ap...\n",
       "144  bctech2155  https://insights.blackcoffer.com/healthcare-da...\n",
       "145  bctech2156  https://insights.blackcoffer.com/budget-sales-...\n",
       "146  bctech2157  https://insights.blackcoffer.com/amazon-buy-bo...\n",
       "\n",
       "[147 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_file = 'Input.xlsx'\n",
    "df = pd.read_excel(input_file)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "836c5b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fce0cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_article_text(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    title = soup.find('h1').get_text()\n",
    "    article = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
    "    return title, article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "620b329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in df.iterrows():\n",
    "    url = row['URL']\n",
    "    url_id = row['URL_ID']\n",
    "    title, article = extract_article_text(url)\n",
    "    with open(f'{url_id}.txt', 'w', encoding='utf-8') as file:\n",
    "        file.write(title + '\\n' + article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf0915b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import re\n",
    "import os\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Load positive and negative words\n",
    "with open('positive-words.txt', 'r') as file:\n",
    "    positive_words = set(file.read().split())\n",
    "with open('negative-words.txt', 'r') as file:\n",
    "    negative_words = set(file.read().split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e249178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    words = word_tokenize(text)\n",
    "    cleaned_words = [word for word in words if word.isalpha() and word.lower() not in stop_words]\n",
    "    return cleaned_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9bd7c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count(word):\n",
    "    word = word.lower()\n",
    "    count = len(re.findall(r'[aeiouy]', word))\n",
    "    if word.endswith('es') or word.endswith('ed'):\n",
    "        count -= 1\n",
    "    return count if count > 0 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3a9e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_scores(text):\n",
    "    cleaned_words = clean_text(text)\n",
    "    total_words = len(cleaned_words)\n",
    "    positive_score = sum(1 for word in cleaned_words if word in positive_words)\n",
    "    negative_score = sum(1 for word in cleaned_words if word in negative_words)\n",
    "    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "    subjectivity_score = (positive_score + negative_score) / (total_words + 0.000001)\n",
    "\n",
    "    sentences = sent_tokenize(text)\n",
    "    avg_sentence_length = total_words / len(sentences)\n",
    "    complex_words = sum(1 for word in cleaned_words if syllable_count(word) > 2)\n",
    "    percentage_complex_words = complex_words / total_words\n",
    "    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n",
    "    avg_words_per_sentence = total_words / len(sentences)\n",
    "    syllables_per_word = sum(syllable_count(word) for word in cleaned_words) / total_words\n",
    "    personal_pronouns = len(re.findall(r'\\b(I|we|my|ours|us)\\b', text, re.I))\n",
    "    avg_word_length = sum(len(word) for word in cleaned_words) / total_words\n",
    "\n",
    "    return [positive_score, negative_score, polarity_score, subjectivity_score, avg_sentence_length,\n",
    "            percentage_complex_words, fog_index, avg_words_per_sentence, complex_words, total_words,\n",
    "            syllables_per_word, personal_pronouns, avg_word_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "124f2d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    url_id = row['URL_ID']\n",
    "    with open(f'{url_id}.txt', 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    scores = calculate_scores(text)\n",
    "    output_data.append([row['URL_ID'], row['URL']] + scores)\n",
    "\n",
    "output_df = pd.DataFrame(output_data, columns=[\n",
    "    'URL_ID', 'URL', 'POSITIVE SCORE', 'NEGATIVE SCORE', 'POLARITY SCORE', 'SUBJECTIVITY SCORE',\n",
    "    'AVG SENTENCE LENGTH', 'PERCENTAGE OF COMPLEX WORDS', 'FOG INDEX', 'AVG NUMBER OF WORDS PER SENTENCE',\n",
    "    'COMPLEX WORD COUNT', 'WORD COUNT', 'SYLLABLE PER WORD', 'PERSONAL PRONOUNS', 'AVG WORD LENGTH'\n",
    "])\n",
    "output_df.to_excel('Output Data Structure.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f829605",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
